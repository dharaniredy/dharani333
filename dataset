{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "datatrain1=pd.read_csv('Batch1e.csv')\n",
    "datatrain2=pd.read_csv('Batch2e.csv')\n",
    "datatrain3=pd.read_csv('Batch3e.csv')\n",
    "datatrain4=pd.read_csv('Batch4e.csv')\n",
    "datatrain5=pd.read_csv('Batch5e.csv')\n",
    "datatrain6=pd.read_csv('Batch6e.csv')\n",
    "datatrain7=pd.read_csv('Batch7e.csv')\n",
    "datatrain8=pd.read_csv('Batch8e.csv')\n",
    "datatrain9=pd.read_csv('Batch9e.csv')\n",
    "datatrain10=pd.read_csv('Batch10e.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change dataframe to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1=np.array(datatrain1)\n",
    "X2=np.array(datatrain2)\n",
    "X3=np.array(datatrain3)\n",
    "X4=np.array(datatrain4)\n",
    "X5=np.array(datatrain5)\n",
    "X6=np.array(datatrain6)\n",
    "X7=np.array(datatrain7)\n",
    "X8=np.array(datatrain8)\n",
    "X9=np.array(datatrain9)\n",
    "X10=np.array(datatrain10)\n",
    "\n",
    "array_list=[X1,X2,X3,X4,X5,X6,X7,X8,X9,X10]\n",
    "sample = np.concatenate([X1, X2])\n",
    "lengths = [len(X1), len(X2)]\n",
    "datatrain_array=np.vstack(array_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split x and y (feature and target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "xtrain = datatrain_array[:,1:130]\n",
    "ytrain = datatrain_array[:,0]\n",
    "\n",
    "max_abs_scaler = MaxAbsScaler()\n",
    "xtrain = max_abs_scaler.fit_transform(xtrain) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(xtrain, ytrain, test_size=.1,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth           : [ 3.  3.  5. ...,  4.  5.  2.]\n",
      "predicted class        : [ 3.  3.  5. ...,  4.  5.  2.]\n",
      "ground truth           : [ 3.  3.  5. ...,  4.  5.  2.]\n",
      "predicted class        : [ 3.  3.  5. ...,  4.  5.  2.]\n",
      "cross validation acc   : 0.839530533181\n"
     ]
    }
   ],
   "source": [
    "#training and testing the model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = LogisticRegression()\n",
    "log=clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred =log.predict(X_test)\n",
    "print('ground truth           :',y_test)\n",
    "print('predicted class        :',y_pred)\n",
    "print('ground truth           :',y_test)\n",
    "print('predicted class        :',y_pred)\n",
    "print('cross validation acc   :',cross_val_score(log,X_test,y_test).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[247   1   0   6   1   1]\n",
      " [  1 295   0   2   1   0]\n",
      " [  0   1 156   7   4   0]\n",
      " [  4   0   0 185   1   4]\n",
      " [  1   0   2   2 302   9]\n",
      " [  0   0   0   6   0 151]]\n",
      "Normalized confusion matrix\n",
      "[[ 0.96  0.    0.    0.02  0.    0.  ]\n",
      " [ 0.    0.99  0.    0.01  0.    0.  ]\n",
      " [ 0.    0.01  0.93  0.04  0.02  0.  ]\n",
      " [ 0.02  0.    0.    0.95  0.01  0.02]\n",
      " [ 0.    0.    0.01  0.01  0.96  0.03]\n",
      " [ 0.    0.    0.    0.04  0.    0.96]]\n"
     ]
    },
    {
     "data": {
     "text/plain": [
       "<matplotlib.figure.Figure at 0x2626f91e550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
     "<matplotlib.figure.Figure at 0x26271e551d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "class_names=['1','2','3','4','5','6']\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "rootdir = 'F:/OneDrive/Research & Study/Thesis Writing/svm_all2.png'\n",
    "plt.savefig(rootdir,figsize=(4,3),dpi=500,bbox_inches='tight',labelsize=12)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Confusion matrix, with normalization')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "rootdir = 'F:/OneDrive/Research & Study/Thesis Writing/svm_all1.png'\n",
    "plt.savefig(rootdir,figsize=(4,3),dpi=500,bbox_inches='tight',labelsize=11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
